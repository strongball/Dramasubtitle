{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "from model.BigModel import SubToSeq\n",
    "from utils.tokenMaker import Lang\n",
    "from utils.tool import padding, flatMutileLength, Timer, Average\n",
    "from dataset.readVideo import DramaDataset\n",
    "useCuda = True\n",
    "device = torch.device(\"cuda\" if useCuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Drama: 134\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data\n",
    "DataDir = \"/home/ball/Videos/Broke\"\n",
    "datasets = DramaDataset(basedir=DataDir,\n",
    "                        maxFrame=0,\n",
    "                        timeOffset=0.2,\n",
    "                        useBmp=True\n",
    "                        )\n",
    "loader = torch.utils.data.DataLoader(datasets, batch_size=5, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load lang model: SubToSub/models/BK_CH_FIX_200/. Word size: 3703\n"
     ]
    }
   ],
   "source": [
    "ModalFile = \"SubToSub/models/BK_CH_FIX_200/\"\n",
    "modal = torch.load(ModalFile+\"SubSubModel.10.pth\")\n",
    "with open(ModalFile+\"Lang.pkl\", 'rb') as f:\n",
    "    lang = pickle.load(f)\n",
    "    print(\"Load lang model: {}. Word size: {}\".format(ModalFile, len(lang)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transData(in_sents, target_sents, lang):\n",
    "    in_seqs = []\n",
    "    in_targets = []\n",
    "    out_targets = []\n",
    "    \n",
    "    vectorTransforms = [lambda x: torch.LongTensor(x).to(device)]\n",
    "    \n",
    "    for sent in in_sents:\n",
    "        in_seqs.append(lang.sentenceToVector(sent, sos=False, eos=False))\n",
    "    in_seqs = padding(in_seqs, lang[\"PAD\"], vectorTransforms)\n",
    "    \n",
    "    for sent in target_sents:\n",
    "        in_targets.append(lang.sentenceToVector(sent, sos=True, eos=False))\n",
    "        out_targets.append(lang.sentenceToVector(sent, sos=False, eos=True))\n",
    "    in_targets = padding(in_targets, lang[\"PAD\"], vectorTransforms)\n",
    "    out_targets = padding(out_targets, lang[\"PAD\"], vectorTransforms)\n",
    "    return in_seqs, in_targets, out_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predit(model, lang, in_sents, max_length=50):\n",
    "    ans = []\n",
    "    in_seq = torch.LongTensor(lang.sentenceToVector(in_sents, sos=False, eos=False)).unsqueeze(0).to(device)\n",
    "    inputs = torch.LongTensor([[lang[\"SOS\"]]]).to(device)\n",
    "    hidden = None\n",
    "    \n",
    "    cxt = model.makeContext(in_seq)\n",
    "    for i in range(max_length):\n",
    "        outputs, hidden = model.decode(inputs, cxt, hidden)\n",
    "        prob, outputs = outputs.topk(1)\n",
    "\n",
    "        if(outputs.item() == lang[\"EOS\"]):\n",
    "            break\n",
    "        ans.append(outputs.item())\n",
    "        inputs = outputs.squeeze(1).detach()\n",
    "    return lang.vectorToSentence(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def showVar(data):\n",
    "    x = range(0, data.size(-1))\n",
    "    plt.bar(x, data.data.cpu())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres, nexs, imgs = it.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre  : 阿憨 你這樣真的太多管閑事了\n",
      "Next : 真是太沒禮貌了 因為多管閑事是我的工作\n",
      "Modal: 比如好消息的情況下冰門一\n",
      "\n",
      "\n",
      "Pre  : 我的最愛\n",
      "Next : 腰果除外\n",
      "Modal: 腰果除外\n",
      "\n",
      "\n",
      "Pre  : 而降低了膽固醇水平的人啊\n",
      "Next : 還有那些因爲我 纔不吃Klamitra的人\n",
      "Modal: 還有那些因爲我 纔不吃Klamitra的人\n",
      "\n",
      "\n",
      "Pre  : 嘿 我又沒喝酒 干嘛要付那酒錢\n",
      "Next : 啊 這可是我抓酸黃瓜的手\n",
      "Modal: 我用的 我要用那筆錢給我買了一包酒店的酒\n",
      "\n",
      "\n",
      "Pre  : 我們家族和Shecter家族私交甚好\n",
      "Next : 其實 他家少爺David還在這實習呢\n",
      "Modal: 其實 他家少爺David還在這實習呢\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modal.eval()\n",
    "for pre, nex in zip(pres, nexs):\n",
    "    pred = predit(modal, lang, pre)\n",
    "    print(\"Pre  : {}\\nNext : {}\\nModal: {}\\n\\n\".format(pre, nex, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
