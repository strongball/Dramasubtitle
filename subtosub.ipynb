{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "import pickle\n",
    "\n",
    "from model.BigModel import SubToSeq\n",
    "from utils.tokenMaker import Lang\n",
    "from utils.tool import padding, flatMutileLength, Timer, Average\n",
    "from dataset.readVideo import DramaDataset\n",
    "useCuda = True\n",
    "device = torch.device(\"cuda\" if useCuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Drama: 113\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data\n",
    "DataDir = \"/home/ball/Videos/BrokeEN\"\n",
    "datasets = DramaDataset(basedir=DataDir,\n",
    "                        maxFrame=0,\n",
    "                        timeOffset=0.2,\n",
    "                        useBmp=True\n",
    "                        )\n",
    "loader = torch.utils.data.DataLoader(datasets, batch_size=5, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load lang model: SubToSub/model/bken-large/. Word size: 15479\n"
     ]
    }
   ],
   "source": [
    "ModalFile = \"SubToSub/model/bken-large/\"\n",
    "modal = torch.load(ModalFile+\"SubSubModel.10.pth\")\n",
    "with open(ModalFile+\"Lang.pkl\", 'rb') as f:\n",
    "    lang = pickle.load(f)\n",
    "    print(\"Load lang model: {}. Word size: {}\".format(ModalFile, len(lang)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transData(in_sents, target_sents, lang):\n",
    "    in_seqs = []\n",
    "    in_targets = []\n",
    "    out_targets = []\n",
    "    \n",
    "    vectorTransforms = [lambda x: torch.LongTensor(x).to(device)]\n",
    "    \n",
    "    for sent in in_sents:\n",
    "        in_seqs.append(lang.sentenceToVector(sent, sos=False, eos=False))\n",
    "    in_seqs = padding(in_seqs, lang[\"PAD\"], vectorTransforms)\n",
    "    \n",
    "    for sent in target_sents:\n",
    "        in_targets.append(lang.sentenceToVector(sent, sos=True, eos=False))\n",
    "        out_targets.append(lang.sentenceToVector(sent, sos=False, eos=True))\n",
    "    in_targets = padding(in_targets, lang[\"PAD\"], vectorTransforms)\n",
    "    out_targets = padding(out_targets, lang[\"PAD\"], vectorTransforms)\n",
    "    return in_seqs, in_targets, out_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predit(model, lang, in_sents, max_length=50):\n",
    "    ans = []\n",
    "    in_seq = torch.LongTensor(lang.sentenceToVector(in_sents, sos=False, eos=False)).unsqueeze(0).to(device)\n",
    "    inputs = torch.LongTensor([[lang[\"SOS\"]]]).to(device)\n",
    "    hidden = None\n",
    "    \n",
    "    cxt = model.makeContext(in_seq)\n",
    "    for i in range(max_length):\n",
    "        outputs, hidden = model.decode(inputs, cxt, hidden)\n",
    "        prob, outputs = outputs.topk(1)\n",
    "\n",
    "        if(outputs.item() == lang[\"EOS\"]):\n",
    "            break\n",
    "        ans.append(outputs.item())\n",
    "        inputs = outputs.squeeze(1).detach()\n",
    "    return lang.vectorToSentence(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def showVar(data):\n",
    "    x = range(0, data.size(-1))\n",
    "    plt.bar(x, data.data.cpu())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres, nexs, imgs = it.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre  : That could ve hit us\n",
      "Next : Now that s unsafe sex\n",
      "Modal: Now that s unsafe sex\n",
      "\n",
      "\n",
      "Pre  : No No it s on the house\n",
      "Next : It s your birthday\n",
      "Modal: It s your birthday\n",
      "\n",
      "\n",
      "Pre  : You re pathetic\n",
      "Next : And that s coming from someone who is homeless\n",
      "Modal: And that s coming from someone who is homeless\n",
      "\n",
      "\n",
      "Pre  : And not the kind where I can loot\n",
      "Next : I needed those fake papers to renew my fake green card\n",
      "Modal: I needed those fake papers to renew my fake green card\n",
      "\n",
      "\n",
      "Pre  : You know that right\n",
      "Next : Well I know I m entitled to my truths and how my truths make me feel\n",
      "Modal: Well I know I m entitled to my truths and how my truths make me feel\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modal.eval()\n",
    "for pre, nex in zip(pres, nexs):\n",
    "    pred = predit(modal, lang, pre)\n",
    "    print(\"Pre  : {}\\nNext : {}\\nModal: {}\\n\\n\".format(pre, nex, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
