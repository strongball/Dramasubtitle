{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'modal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e369a66d99cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBigModal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSubToSeq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenMaker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatMutileLength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAverage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'modal'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "\n",
    "from modal.BigModal import SubToSeq\n",
    "from utils.tokenMaker import Lang\n",
    "from utils.tool import padding, flatMutileLength, Timer, Average\n",
    "useCuda = True\n",
    "Variable = Variable.cuda if useCuda else Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "import pickle\n",
    "with open(\"./translate/eng_fra_dataset\", 'rb') as f:\n",
    "    trainset = pickle.load(f)\n",
    "    \n",
    "loader = torch.utils.data.DataLoader(trainset, batch_size=5, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.translate import TranslateDataset as DramaDataset\n",
    "datasets = DramaDataset(basedir=\"./translate/eng_fra_dataset\",\n",
    "                        maxFrame=0,\n",
    "                        timeOffset=0.2,\n",
    "                        startSeries=1,\n",
    "                        maxSeries=5,\n",
    "                        subOffset=0, \n",
    "                        subMax=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('j ai demande a maintes reprises aux villageois de me laisser mourir .',\n",
       " 'i asked the villagers many times to let me die .',\n",
       " [])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load lang model: TransModal/overtrain/. Word size: 32107\n"
     ]
    }
   ],
   "source": [
    "ModalFile = \"TransModal/overtrain/\"\n",
    "modal = torch.load(ModalFile+\"SubSubModal.180.pth\")\n",
    "with open(ModalFile+\"Lang.pkl\", 'rb') as f:\n",
    "    lang = pickle.load(f)\n",
    "    print(\"Load lang model: {}. Word size: {}\".format(ModalFile, len(lang)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transData(in_sents, target_sents, lang):\n",
    "    in_seqs = []\n",
    "    in_targets = []\n",
    "    out_targets = []\n",
    "    \n",
    "    vectorTransforms = [torch.LongTensor, Variable]\n",
    "    \n",
    "    for sent in in_sents:\n",
    "        in_seqs.append(lang.sentenceToVector(sent, sos=False, eos=False))\n",
    "    in_seqs = padding(in_seqs, lang[\"PAD\"], vectorTransforms)\n",
    "    \n",
    "    for sent in target_sents:\n",
    "        in_targets.append(lang.sentenceToVector(sent, sos=True, eos=False))\n",
    "        out_targets.append(lang.sentenceToVector(sent, sos=False, eos=True))\n",
    "    in_targets = padding(in_targets, lang[\"PAD\"], vectorTransforms)\n",
    "    out_targets = padding(out_targets, lang[\"PAD\"], vectorTransforms)\n",
    "    return in_seqs, in_targets, out_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predit(modal, lang, in_sents, max_length=50):\n",
    "    ans = []\n",
    "    in_seq = Variable(torch.LongTensor(lang.sentenceToVector(in_sents, sos=False, eos=False)).unsqueeze(0))\n",
    "    inputs = Variable(torch.LongTensor([[lang[\"SOS\"]]]).long())\n",
    "    hidden = None\n",
    "    \n",
    "    cxt = modal.makeContext(in_seq)\n",
    "    for i in range(max_length):\n",
    "        outputs, hidden = modal.decode(inputs, cxt, hidden)\n",
    "        prob, outputs = outputs.topk(1)\n",
    "        outputs = outputs[0][0].data[0]\n",
    "        if(outputs == lang[\"EOS\"]):\n",
    "            break\n",
    "        ans.append(outputs)\n",
    "        inputs = Variable(torch.LongTensor([[outputs]]))\n",
    "    return lang.vectorToSentence(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def showVar(data):\n",
    "    x = range(0, data.size(-1))\n",
    "    plt.bar(x, data.data.cpu())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fras, engs = it.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fra: sors de ma chambre immediatement .\n",
      "Eng: leave my room immediately .\n",
      "Pre: get out of my PAD right .\n",
      "\n",
      "\n",
      "Fra: leur fille est infirmiere .\n",
      "Eng: their daughter is a nurse .\n",
      "Pre: their daughter is a nurse .\n",
      "\n",
      "\n",
      "Fra: verifie !\n",
      "Eng: check it out !\n",
      "Pre: come on .\n",
      "\n",
      "\n",
      "Fra: le monde est il devenu fou ?\n",
      "Eng: has the world gone mad ?\n",
      "Pre: has the world big become ?\n",
      "\n",
      "\n",
      "Fra: qui etes vous et que voulez vous ?\n",
      "Eng: who are you and what do you want ?\n",
      "Pre: who are you and what do you want ?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modal.eval()\n",
    "for fra, eng in zip(fras, engs):\n",
    "    pred = predit(modal, lang, fra)\n",
    "    print(\"Fra: {}\\nEng: {}\\nPre: {}\\n\\n\".format(fra, eng, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_seq = Variable(torch.LongTensor(lang.sentenceToVector(fras[1], sos=False, eos=False)).unsqueeze(0))\n",
    "inputs = Variable(torch.LongTensor([[lang[\"SOS\"]]]).long())\n",
    "hidden = None\n",
    "\n",
    "cxt = modal.makeContext(in_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, hidden = modal.decode(inputs, cxt, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD6CAYAAAC1W2xyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJamY/wfviXav1ZxNQgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showVar(outputs[0,0,2000:2200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " (0 ,.,.) = \n",
       "   0.9976  0.0022  0.0001\n",
       " [torch.cuda.FloatTensor of size 1x1x3 (GPU 0)], Variable containing:\n",
       " (0 ,.,.) = \n",
       "   2056   457   222\n",
       " [torch.cuda.LongTensor of size 1x1x3 (GPU 0)])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.topk(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
